{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06-what-is-torch_nn-exactly.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNihuyL3rZ4YSx8XFiOQ4nH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"LIEg0oTX4tnw","colab_type":"text"},"source":["PyTorch provides the elegantly designed modules and classes `torch.nn` , `torch.optim` , `Dataset` , and `DataLoader` to help us create and train neural networks. In order to fully utilize their power and customize them for our problem, we need to **really** understand exactly what they’re doing.\n","\n","To develop this understanding, \n","- we will first train basic neural net on the MNIST data set without using any features from these models; we will initially only use the most basic PyTorch tensor functionality. \n","- Then, we will incrementally add one feature from `torch.nn`, `torch.optim`, `Dataset`, or `DataLoader` at a time, showing exactly what each piece does, and how it works to make the code either more concise, or more flexible."]},{"cell_type":"markdown","metadata":{"id":"AAN1LjJttE5B","colab_type":"text"},"source":["## MNIST data setup\n","\n","We will use the classic MNIST dataset, which consists of black-and-white images of hand-drawn digits (between 0 and 9).\n","\n","We will use pathlib for dealing with paths (part of the Python 3 standard library), and will download the dataset using requests. We will only import modules when we use them."]},{"cell_type":"code","metadata":{"id":"O5Ys-rbJ4g6l","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014960679,"user_tz":-120,"elapsed":1088,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["from pathlib import Path\n","import requests"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"wpXhF5LD4jQb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014963550,"user_tz":-120,"elapsed":3953,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["DATA_PATH = Path(\"data\")\n","PATH = DATA_PATH / \"mnist\"\n","\n","PATH.mkdir(parents=True, exist_ok=True)\n","\n","URL = \"http://deeplearning.net/data/mnist/\"\n","FILENAME = \"mnist.pkl.gz\"\n","\n","if not (PATH / FILENAME).exists():\n","        content = requests.get(URL + FILENAME).content\n","        (PATH / FILENAME).open(\"wb\").write(content)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EIYQzMdsAKib","colab_type":"text"},"source":["This dataset is in numpy array format, and has been stored using pickle, a python-specific format for serializing data."]},{"cell_type":"code","metadata":{"id":"u24h1UEmAgrh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014964103,"user_tz":-120,"elapsed":4501,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["import pickle\n","import gzip\n","\n","with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n","        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wsP65uX6AhIf","colab_type":"text"},"source":["Each image is 28 x 28, and is being stored as a flattened row of length 784 (=28x28). \n","\n","Let’s take a look at one; we need to reshape it to 2d first."]},{"cell_type":"code","metadata":{"id":"NTxeAQiPAmvr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014964105,"user_tz":-120,"elapsed":4496,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"VJCgQHoaAsyH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"status":"ok","timestamp":1600014964105,"user_tz":-120,"elapsed":4488,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"bc8a4490-8548-4b8c-b02d-fa827a68ae81"},"source":["plt.imshow(x_train[0].reshape(28, 28), cmap=\"gray\")\n","print(x_train.shape)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["(50000, 784)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"p5x0PPwsA0qf","colab_type":"text"},"source":["PyTorch uses `torch.tensor` instead of numpy arrays. So we need to convert the data"]},{"cell_type":"code","metadata":{"id":"4fenx6obBDhX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014967727,"user_tz":-120,"elapsed":8102,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["import torch"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"3P3pIWeMBFEY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014967730,"user_tz":-120,"elapsed":8099,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["x_train, y_train, x_valid, y_valid = map(\n","    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",")\n","\n","n, c = x_train.shape"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"JUiVqN2PBaGK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1600014967730,"user_tz":-120,"elapsed":8091,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"fcc045eb-a92c-406c-8354-a15b62f24ef4"},"source":["print(x_train, y_train)\n","print(f\"Shape of training data: {x_train.shape}\")\n","print(f\"min label: {y_train.min()}, max label: {y_train.max()}\")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n","Shape of training data: torch.Size([50000, 784])\n","min label: 0, max label: 9\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qbbIil8rCIMu","colab_type":"text"},"source":["## Neural net from scratch (no torch.nn)\n","\n","Let’s first create a model using nothing but PyTorch tensor operations.\n","\n","Note: We are initializing the weights here with [Xavier](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) initialisation (by multiplying with 1/sqrt(n))."]},{"cell_type":"code","metadata":{"id":"G1KgKyD8ev9N","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014967731,"user_tz":-120,"elapsed":8082,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["import math\n","\n","weights = torch.randn(784, 10) / math.sqrt(784)\n","weights.requires_grad_()\n","bias = torch.zeros(10, requires_grad=True)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gbSkDeqxfOYw","colab_type":"text"},"source":["Thanks to PyTorch’s ability to calculate gradients automatically, we can use any standard Python function (or callable object) as a model! Here we write a plain matrix multiplication and broadcasted addition to create a simple linear model.\n","\n","For activation function we'll write *log_softmax*.\n","(Although PyTorch provides lots of pre-written loss functions, activation functions, and so forth, you can easily write your own using plain python. PyTorch will even create fast GPU or vectorized CPU code for your function automatically.)"]},{"cell_type":"code","metadata":{"id":"oN4QHFtef1rS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014967732,"user_tz":-120,"elapsed":8078,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["def log_softmax(x):\n","    return x - x.exp().sum(-1).log().unsqueeze(-1)\n","\n","def model(xb):\n","    return log_softmax(xb @ weights + bias)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3ZSS0JsgFK4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600014967732,"user_tz":-120,"elapsed":8070,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"3b4a74e9-f6d8-4dae-c20f-a83a4ca9e97e"},"source":["x = torch.tensor([1.0,2,3,4])\n","x - x.exp()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ -1.7183,  -5.3891, -17.0855, -50.5981])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"8u-FQgb8iZV-","colab_type":"text"},"source":["We will call our function on one batch of data (in this case, 64 images). This is one forward pass. Note that our predictions won’t be any better than random at this stage, since we start with random weights."]},{"cell_type":"code","metadata":{"id":"xiXA_BVUjAM1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600014968159,"user_tz":-120,"elapsed":8484,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"24cabe9a-3d83-443f-d98c-4445dbe20f8f"},"source":["bs = 64 # batch size\n","\n","xb = x_train[0:bs] # a mini-batch from x\n","preds = model(xb)\n","preds[0], preds.shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([-1.7520, -2.1178, -1.9868, -2.7721, -2.1494, -2.4752, -2.4750, -2.6911,\n","         -2.3647, -2.8141], grad_fn=<SelectBackward>), torch.Size([64, 10]))"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"_2iaNSppjJln","colab_type":"text"},"source":["Let's implement negative log-likelihood as the loss function:"]},{"cell_type":"code","metadata":{"id":"w8c8WIESjfqC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014968160,"user_tz":-120,"elapsed":8478,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["def neg_log_lik(input, target):\n","    return -input[range(target.shape[0]), target].mean()\n","\n","loss_fn = neg_log_lik"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wNp_V0Tlj1lk","colab_type":"text"},"source":["Loss with our random model:"]},{"cell_type":"code","metadata":{"id":"mo1FQMl4j6eo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600014968161,"user_tz":-120,"elapsed":8471,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"43495869-52a5-45d3-e7cc-6339a7be2aa9"},"source":["yb = y_train[0:bs]\n","loss_fn(preds, yb)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.3094, grad_fn=<NegBackward>)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"ZueIbj55kEDe","colab_type":"text"},"source":["Calculate the accuracy of the model: For each prediction, if the index with the largest value matches the target value, then the prediction was correct.\n","\n"]},{"cell_type":"code","metadata":{"id":"sshjnYzckdzf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600014968163,"user_tz":-120,"elapsed":8462,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"f1f5fd50-b6d2-4014-c138-07fa49d78268"},"source":["def accuracy(out, yb):\n","    preds = torch.argmax(out, dim=1)\n","    return (preds == yb).float().mean()\n","\n","accuracy(preds, yb)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.1719)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"3RqqXj-8koEb","colab_type":"text"},"source":["We can now run a training loop. For each iteration, we will:\n","\n","- select a mini-batch of data (of size `bs`)\n","- use the model to make predictions\n","- calculate the loss\n","- `loss.backward()` updates the gradients of the model, in this case, `weights` and `bias`.\n","\n","Note:\n","- By using gradients to update the weights and bias, we do this within the `torch.no_grad()` context manager, because we do not want these actions to be recorded for our next calculation of the gradient.\n","\n","- We then set the gradients to zero, so that we are ready for the next loop. Otherwise, our gradients would record a running tally of all the operations that had happened (i.e. `loss.backward()` adds the gradients to whatever is already stored, rather than replacing them)."]},{"cell_type":"code","metadata":{"id":"8frlOYuQo4fS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"status":"ok","timestamp":1600014968604,"user_tz":-120,"elapsed":8893,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"0d2f3b71-c7d9-4f09-d388-442027a66d7f"},"source":["from IPython.core.debugger import set_trace\n","\n","lr = 0.5 # learning rate\n","epochs = 2 # epochs to train for\n","\n","for epoch in range(epochs):\n","    for i in range((n - 1) // bs + 1):\n","        # set_trace()\n","        start_i = i * bs\n","        end_i = start_i + bs\n","        xb = x_train[start_i:end_i]\n","        yb = y_train[start_i:end_i]\n","        pred = model(xb)\n","        loss = loss_fn(pred, yb)\n","        if i % 50 == 0:\n","            print(f\"[epoch {epoch + 1}, iter {i}]: {loss}\")\n","\n","        loss.backward()\n","\n","        with torch.no_grad():\n","            # update weights\n","            weights -= weights.grad * lr\n","            bias -= bias.grad * lr\n","\n","            # zero grad for next loop\n","            weights.grad.zero_()\n","            bias.grad.zero_()\n","\n","\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[epoch 1, iter 0]: 2.3093509674072266\n","[epoch 1, iter 50]: 0.4197274446487427\n","[epoch 1, iter 100]: 0.3120243549346924\n","[epoch 1, iter 150]: 0.28343045711517334\n","[epoch 1, iter 200]: 0.300825834274292\n","[epoch 1, iter 250]: 0.5515051484107971\n","[epoch 1, iter 300]: 0.3799591064453125\n","[epoch 1, iter 350]: 0.3051801323890686\n","[epoch 1, iter 400]: 0.23816058039665222\n","[epoch 1, iter 450]: 0.21838515996932983\n","[epoch 1, iter 500]: 0.3832177519798279\n","[epoch 1, iter 550]: 0.35959625244140625\n","[epoch 1, iter 600]: 0.2618858218193054\n","[epoch 1, iter 650]: 0.24013422429561615\n","[epoch 1, iter 700]: 0.3840702474117279\n","[epoch 1, iter 750]: 0.2189883291721344\n","[epoch 2, iter 0]: 0.27328863739967346\n","[epoch 2, iter 50]: 0.33668485283851624\n","[epoch 2, iter 100]: 0.2601320445537567\n","[epoch 2, iter 150]: 0.2008134424686432\n","[epoch 2, iter 200]: 0.19638781249523163\n","[epoch 2, iter 250]: 0.4840746223926544\n","[epoch 2, iter 300]: 0.33805814385414124\n","[epoch 2, iter 350]: 0.2569262385368347\n","[epoch 2, iter 400]: 0.21170902252197266\n","[epoch 2, iter 450]: 0.17897477746009827\n","[epoch 2, iter 500]: 0.35483530163764954\n","[epoch 2, iter 550]: 0.3222004771232605\n","[epoch 2, iter 600]: 0.22470581531524658\n","[epoch 2, iter 650]: 0.20504659414291382\n","[epoch 2, iter 700]: 0.3665522336959839\n","[epoch 2, iter 750]: 0.19300062954425812\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qLf5eNDCqNWK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600014968604,"user_tz":-120,"elapsed":8883,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"ca3e6dc1-28cf-4e0f-c1e0-a70630b31c89"},"source":["print(f\"loss: {loss_fn(model(xb), yb)}\")\n","print(f\"accuracy: {accuracy(model(xb), yb)}\")"],"execution_count":18,"outputs":[{"output_type":"stream","text":["loss: 0.08314824104309082\n","accuracy: 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"imJUv_QWrAQf","colab_type":"text"},"source":["That’s it: we’ve created and trained a minimal neural network (in this case, a logistic regression, since we have no hidden layers) entirely from scratch!"]},{"cell_type":"markdown","metadata":{"id":"J3j56rMsrIPf","colab_type":"text"},"source":["## Using `torch.nn.functional`\n","\n","Now we refactor our code, so that it does the same thing as before, only we’ll start taking advantage of PyTorch’s `nn` classes to make it more concise and flexible.\n","\n","- Replace our hand-written activation and loss functions with those from `torch.nn.functional` (which is generally imported into the namespace `F` by convention)\n","    - If we're using negative log likelihood and log softmax activation, we can use `F.cross_entropy` that combines these two. So we can even remove the activation function from our model."]},{"cell_type":"code","metadata":{"id":"CduPcNtqz7Re","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014968605,"user_tz":-120,"elapsed":8876,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["import torch.nn.functional as F\n","\n","loss_fn = F.cross_entropy\n","\n","def model(xb):\n","    return xb @ weights + bias # No call log_softmax in the model"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"0arAp1KH0Ewa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600014968605,"user_tz":-120,"elapsed":8868,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"5a4d6b72-05c3-4f90-f712-e585a64b4504"},"source":["print(f\"loss: {loss_fn(model(xb), yb)}\")\n","print(f\"accuracy: {accuracy(model(xb), yb)}\")"],"execution_count":20,"outputs":[{"output_type":"stream","text":["loss: 0.083148293197155\n","accuracy: 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"laQ7hv2SH3uR","colab_type":"text"},"source":["## Refactor using `nn.Module`\n","\n","Now we'll use `nn.Module` and `nn.Parameter` for a clearer and more concise training loop. Subclassing `nn.Module`, we create a class that holds our weights, biasm and method for the forward step."]},{"cell_type":"code","metadata":{"id":"bAwtBJTEVOvX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014968606,"user_tz":-120,"elapsed":8861,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["from torch import nn\n","\n","class Mnist_Logistic(nn.Module):\n","    \n","    def __init__(self):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n","        self.bias = nn.Parameter(torch.zeros(10))\n","\n","    def forward(self, xb):\n","        return xb @ self.weights + self.bias\n"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"lhKBuQstXBTl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014968606,"user_tz":-120,"elapsed":8857,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["model = Mnist_Logistic()"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S2Dn3S29VskH","colab_type":"text"},"source":["`nn.Module` objects are used as if they are functions (i.e they are *callable*), but behind the scenes Pytorch will call our `forward` method automatically.\n","\n"]},{"cell_type":"code","metadata":{"id":"tUwAtiSwV9mX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600014968607,"user_tz":-120,"elapsed":8850,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"c5f39a73-34b4-4113-8072-35ad343dc2b1"},"source":["print(f\"loss: {loss_fn(model(xb), yb)}\")\n","print(f\"accuracy: {accuracy(model(xb), yb)}\")"],"execution_count":23,"outputs":[{"output_type":"stream","text":["loss: 2.3011975288391113\n","accuracy: 0.0625\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VOM-9fLIV-75","colab_type":"text"},"source":["Previously for our training loop we had to update the values for each parameter by name, and manually zero out the grads for each parameter separately, like this:\n","\n","```python\n","with torch.no_grad():\n","    weights -= weights.grad * lr\n","    bias -= bias.grad * lr\n","    weights.grad.zero_()\n","    bias.grad.zero_()\n","```"]},{"cell_type":"markdown","metadata":{"id":"ddMv_Dd0WHP_","colab_type":"text"},"source":["Now we can take advantage of `model.parameters()` and `model.zero_grad()` (which are both defined by PyTorch for `nn.Module`) to make those steps more concise and less prone to the error of forgetting some of our parameters\n","\n","```python\n","with torch.no_grad():\n","    for p in model.parameters():\n","        p -= p.grad * lr \n","    model.zero_grad()\n","```"]},{"cell_type":"markdown","metadata":{"id":"sA-YuHeQWfT-","colab_type":"text"},"source":["Now let's wrap our training loop in a `fit()` function:"]},{"cell_type":"code","metadata":{"id":"u-DDfh9RXckW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014969231,"user_tz":-120,"elapsed":9467,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["def fit():\n","    for epoch in range(epochs):\n","        for i in range((n-1) // bs + 1):\n","            start_i = i * bs\n","            end_i = start_i + bs\n","            xb = x_train[start_i:end_i]\n","            yb = y_train[start_i:end_i]\n","            pred = model(xb)\n","            loss = loss_fn(pred, yb)\n","\n","            loss.backward()\n","            with torch.no_grad():\n","                for p in model.parameters():\n","                    p -= p.grad * lr\n","                model.zero_grad()\n","\n","fit()"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZB2kyoKpXooI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600014969233,"user_tz":-120,"elapsed":9461,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"9dd1a11c-9a86-4a23-e1cd-9182e6786d02"},"source":["# Print and check the result\n","print(f\"loss: {loss_fn(model(xb), yb)}\")\n","print(f\"accuracy: {accuracy(model(xb), yb)}\")"],"execution_count":25,"outputs":[{"output_type":"stream","text":["loss: 0.08175675570964813\n","accuracy: 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6xOkdWF6XxiE","colab_type":"text"},"source":["## Refactor using `nn.Linear`\n","\n","Instead of manually defining and initializing `self.weights` and `self.bias`, and calculating `xb  @ self.weights + self.bias`, we will instead use the Pytorch class `nn.Linear` for a linear layer, which does all that for us. Pytorch has many types of predefined layers that can greatly simplify our code, and often makes it faster too."]},{"cell_type":"code","metadata":{"id":"aObSr512YQ5P","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014969233,"user_tz":-120,"elapsed":9454,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["class Mnist_Logistic(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.lin = nn.Linear(784, 10)\n","\n","    def forward(self, xb):\n","        return self.lin(xb)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"oc6_WahNYf-u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600014969234,"user_tz":-120,"elapsed":9448,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"b24b857b-0f6d-4469-a295-8663ef414817"},"source":["model = Mnist_Logistic()\n","print(loss_fn(model(xb), yb))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["tensor(2.4157, grad_fn=<NllLossBackward>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DJ7TcMlLYgiQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600014969617,"user_tz":-120,"elapsed":9821,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"c72a207b-a2ef-4a47-e16c-632d9159b9b0"},"source":["fit()\n","\n","print(f\"loss: {loss_fn(model(xb), yb)}\")\n","print(f\"accuracy: {accuracy(model(xb), yb)}\")"],"execution_count":28,"outputs":[{"output_type":"stream","text":["loss: 0.08121129870414734\n","accuracy: 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_qopQMUKYlwf","colab_type":"text"},"source":["## Refactor using `optim`\n","\n","Pytorch also has a package with various optimization algorithms, `torch.optim`. We can use the `step` method from our optimizer to take a forward step, instead of manually updating each parameter.\n","\n","(`optim.zero_grad()` resets the gradient to 0 and we need to call it before computing the gradient for the next minibatch.)\n","\n"]},{"cell_type":"code","metadata":{"id":"SQxBhNPKaoSC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014969618,"user_tz":-120,"elapsed":9815,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["from torch import optim"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCQlzHNea34s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600014969978,"user_tz":-120,"elapsed":10168,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"cfef0aea-7c04-4485-f981-54230b08b7a4"},"source":["def get_model():\n","    model = Mnist_Logistic()\n","    return model, optim.SGD(model.parameters(), lr=lr)\n","\n","model, opt = get_model()\n","print(loss_fn(model(xb), yb))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["tensor(2.3672, grad_fn=<NllLossBackward>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AuREO8tObFrf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600014970344,"user_tz":-120,"elapsed":10523,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"5ba85d3a-8ca6-4689-b583-1d9c6062934b"},"source":["for epoch in range(epochs):\n","    for i in range((n-1) // bs + 1):\n","            start_i = i * bs\n","            end_i = start_i + bs\n","            xb = x_train[start_i:end_i]\n","            yb = y_train[start_i:end_i]\n","            pred = model(xb)\n","            loss = loss_fn(pred, yb)\n","\n","            loss.backward()\n","            opt.step()\n","            opt.zero_grad()\n","\n","print(f\"loss: {loss_fn(model(xb), yb)}\")\n","print(f\"accuracy: {accuracy(model(xb), yb)}\")"],"execution_count":31,"outputs":[{"output_type":"stream","text":["loss: 0.08056163787841797\n","accuracy: 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EmZ88eaabWX3","colab_type":"text"},"source":["## Refactor using `Dataset`\n","\n","PyTorch has an abstract Dataset class. A Dataset can be anything that has\n","\n","- `__len__` function\n","- `__getitem__` function \n","\n","PyTorch’s TensorDataset is a Dataset wrapping tensors. By defining a length and way of indexing, this also gives us a way to iterate, index, and slice along the first dimension of a tensor. This will make it easier to access both the independent and dependent variables in the same line as we train."]},{"cell_type":"code","metadata":{"id":"8_q_9FCDcPMI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014970344,"user_tz":-120,"elapsed":10515,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["from torch.utils.data import TensorDataset"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sUYLK2CacTHd","colab_type":"text"},"source":["Both `x_train` and `y_train` can be combined in a single `TensorDataset`, which will be easier to iterate over and slice."]},{"cell_type":"code","metadata":{"id":"OfULOBst1FFp","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014970345,"user_tz":-120,"elapsed":10511,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["train_ds = TensorDataset(x_train, y_train)"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lXnAbkZQ1MJz","colab_type":"text"},"source":["Previously we had to iterate through mini-batches of x and y values separately\n","\n","```python\n","xb = x_train[start_i:end_i]\n","yb = y_train[start_i:end:i]\n","```\n","\n","Now we can do these two steps together:\n","\n","```python\n","xb, yb = train_ds[i*bs : i*bs+bs]\n","```"]},{"cell_type":"code","metadata":{"id":"b70Y5NsY1lDd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600014970742,"user_tz":-120,"elapsed":10900,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"98dee842-df88-4d5a-abdf-4d2297e8b193"},"source":["model, opt = get_model()\n","\n","for epoch in range(epochs):\n","    for i in range((n - 1) // bs + 1):\n","        xb, yb = train_ds[i * bs : i * bs + bs]\n","        pred = model(xb)\n","        loss = loss_fn(pred, yb)\n","        loss.backward()\n","        opt.step()\n","        opt.zero_grad()\n","\n","print(f\"loss: {loss_fn(model(xb), yb)}\")\n","print(f\"accuracy: {accuracy(model(xb), yb)}\")"],"execution_count":34,"outputs":[{"output_type":"stream","text":["loss: 0.08123419433832169\n","accuracy: 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q-HFt6a54iiF","colab_type":"text"},"source":["## Refactor using DataLoader\n","\n","PyTorch's `DataLoader` is responsible for managing batches. We can create a `DataLoader` from any `Dataset`. Rather than having to use `train_ds[i*bs : i*bs+bs]`, the DataLoader gives us each minibatch automatically."]},{"cell_type":"code","metadata":{"id":"kfTSSsTQ5Dc0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014970743,"user_tz":-120,"elapsed":10893,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["from torch.utils.data import DataLoader\n","\n","train_ds = TensorDataset(x_train, y_train)\n","train_dl = DataLoader(train_ds, batch_size=bs)"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"76v-P1xj5OlP","colab_type":"text"},"source":["Previously, our loop iterated over batches (xb, yb) like this:\n","\n","```python\n","for i in range((n-1)//bs + 1):\n","    xb,yb = train_ds[i*bs : i*bs+bs]\n","    pred = model(xb)\n","```\n","\n","Now, our loop is much cleaner, as (xb, yb) are loaded automatically from the data loader:\n","\n","```python\n","for xb, yb in train_dl:\n","    pred = model(xb)\n","```"]},{"cell_type":"code","metadata":{"id":"7t5FfS6u5g6-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600014971730,"user_tz":-120,"elapsed":11872,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"a430d33c-4448-4ec4-a8e0-00a74d4e7fe9"},"source":["model, opt = get_model()\n","\n","for epoch in range(epochs):\n","    for xb, yb in train_dl:\n","        pred = model(xb)\n","        loss = loss_fn(pred, yb)\n","\n","        loss.backward()\n","        opt.step()\n","        opt.zero_grad()\n","\n","print(f\"loss: {loss_fn(model(xb), yb)}\")\n","print(f\"accuracy: {accuracy(model(xb), yb)}\")"],"execution_count":36,"outputs":[{"output_type":"stream","text":["loss: 0.08228730410337448\n","accuracy: 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XOPvGSl15tv-","colab_type":"text"},"source":["Now our training loop is dramatically smaller and easier to understand!"]},{"cell_type":"markdown","metadata":{"id":"frVaa-Cu6TH7","colab_type":"text"},"source":["## Add Validation\n","\n","In order to identify overfitting, we always should also have a **validation set**\n","\n","**Shuffling the training data** is important to prevent correlation between batches and overfitting. \n","On the other hand, the validation loss will be identical whether we shuffle the validation set or not. Since shuffling takes extra time, **it makes no sense to shuffle the validation data**.\n","\n","We’ll use a batch size for the validation set that is twice as large as that for the training set. This is because the validation set does not need backpropagation and thus takes less memory (it doesn’t need to store the gradients). We take advantage of this to use a larger batch size and compute the loss more quickly."]},{"cell_type":"code","metadata":{"id":"Sdaz6ht06waD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014971731,"user_tz":-120,"elapsed":11865,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["train_ds = TensorDataset(x_train, y_train)\n","train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n","\n","valid_ds = TensorDataset(x_valid, y_valid)\n","valid_dl = DataLoader(valid_ds, batch_size=bs*2)"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oy1Ihrwx7r5U","colab_type":"text"},"source":["Now we will calculate and print the validation loss at the end of each epoch.\n","\n","(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as `nn.BatchNorm2d` and `nn.Dropout` to ensure appropriate behaviour for these different phases.)"]},{"cell_type":"code","metadata":{"id":"98h6olZu7-7Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600014972958,"user_tz":-120,"elapsed":13085,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"f6fcfe4a-d863-4121-a891-3e7b4b3a11af"},"source":["model, opt = get_model()\n","\n","for epoch in range(epochs):\n","    model.train() # call before training\n","    for xb, yb in train_dl:\n","        pred = model(xb)\n","        loss = loss_fn(pred, yb)\n","        loss.backward()\n","        opt.step()\n","        opt.zero_grad()\n","\n","    model.eval()\n","    with torch.no_grad():\n","        valid_loss = sum(loss_fn(model(xb), yb) for xb, yb in valid_dl)\n","    print(f\"{epoch}: {valid_loss / len(valid_dl)}\")"],"execution_count":38,"outputs":[{"output_type":"stream","text":["0: 0.3795289993286133\n","1: 0.303415447473526\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Aat5EgUH87gN","colab_type":"text"},"source":["## Create `fit()` and `get_data()`\n","\n","Since we go through a similar process twice of calculating the loss for both the training set and the validation set, let’s make that into its own function, `loss_batch`, which computes the loss for one batch.\n","\n","- For training set, we pass an optimizer in and use it to perform backprop\n","\n","- For validation set, we don't pass any optimizer, so the methdo doesn't perform backprop\n","\n"]},{"cell_type":"code","metadata":{"id":"pMsOOeuy9fbY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014972958,"user_tz":-120,"elapsed":13075,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["def loss_batch(model, loss_fn, xb, yb, opt=None):\n","    loss = loss_fn(model(xb), yb)\n","\n","    # only perform backprop when for training set \n","    # (i.e., an optimizer is specified)\n","    if opt is not None:\n","        loss.backward()\n","        opt.step()\n","        opt.zero_grad()\n","    \n","    return loss.item(), len(xb)"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Zk35Oru996f","colab_type":"text"},"source":["`fit` runs the necessary operations to train our model and compute the training and validation losses for each epoch."]},{"cell_type":"code","metadata":{"id":"E3IRav_A-AkD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014972959,"user_tz":-120,"elapsed":13070,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["import numpy as np\n","\n","def fit(epochs, model, loss_fn, opt, train_dl, valid_dl):\n","    for epoch in range(epochs):\n","        model.train()\n","        for xb, yb in train_dl:\n","            loss_batch(model, loss_fn, xb, yb, opt)\n","\n","        model.eval()\n","        with torch.no_grad():\n","            losses, nums = zip(\n","                *[loss_batch(model, loss_fn, xb, yb) for xb, yb in valid_dl]\n","            )\n","        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n","\n","        print(epoch, val_loss)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"9tl7TX-QBmqM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014972959,"user_tz":-120,"elapsed":13065,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["def get_data(train_ds, valid_ds, bs):\n","    \"\"\"\n","    returns dataloaders for the training and validation sets\n","    \"\"\"\n","    return (\n","        DataLoader(train_ds, batch_size=bs, shuffle=True),\n","        DataLoader(valid_ds, batch_size=bs * 2),\n","    )"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vEftLUNRB3QZ","colab_type":"text"},"source":["Now, our whole process of obtaining the data loaders and fitting the model can be run in 3 lines of code:"]},{"cell_type":"code","metadata":{"id":"HLxqR5c4B4aO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600014974148,"user_tz":-120,"elapsed":14247,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"1c43f0d1-dc94-4bc5-a4cb-4485868fc243"},"source":["train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n","model, opt = get_model()\n","fit(epochs, model, loss_fn, opt, train_dl, valid_dl)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["0 0.3262045997142792\n","1 0.38030795736312867\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dAvMEr48CE1E","colab_type":"text"},"source":["## Switch to CNN\n","\n","Let's see if we can use these 3 lines of code to train a CNN.\n","\n","We are going to build our neural network with 3 convolutional layers\n","- We will use PyTorch's predefined `Conv2d` class as our convolutional layer\n","- Each convolutional is followed by a ReLU\n","\n","At the end, we perform an average pooling."]},{"cell_type":"code","metadata":{"id":"xmVbRIiZHFPi","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014974149,"user_tz":-120,"elapsed":14240,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["class Mnist_CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n","        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n","        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, xb):\n","        xb = xb.view(-1, 1, 28, 28) # view() is PyTorch's version of numpy's reshape\n","        xb = F.relu(self.conv1(xb))\n","        xb = F.relu(self.conv2(xb))\n","        xb = F.relu(self.conv3(xb))\n","        xb = F.avg_pool2d(xb, 4)\n","        return xb.view(-1, xb.size(1))\n"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"VeT2GwDjH0WV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600014983765,"user_tz":-120,"elapsed":23848,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"0974e946-53e0-43bc-de9a-7673571f4c57"},"source":["lr = 0.1\n","model = Mnist_CNN()\n","opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n","\n","fit(epochs, model, loss_fn, opt, train_dl, valid_dl)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["0 0.3182771824061871\n","1 0.24366851032972336\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EWPYBs7EIclL","colab_type":"text"},"source":["`nn.Sequential`\n","\n","`torch.nn` has another handy class to simply our code: `Sequential`. A `Sequential` object runs each of the modules contained within it, in a sequential manner. This is a simpler way of writing our neural network.\n","\n","To take advantage of this, we need to be able to easily define a **custom layer** from a given function. For instance, PyTorch doesn’t have a view layer, and we need to create one for our network."]},{"cell_type":"code","metadata":{"id":"XDmo816wMmkX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014983766,"user_tz":-120,"elapsed":23838,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["class Lambda(nn.Module):\n","    def __init__(self, func):\n","        super().__init__()\n","        self.func = func\n","\n","    def forward(self, x):\n","        return self.func(x)\n","\n","def preprocess(x):\n","    return x.view(-1, 1, 28, 28)\n"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"6NjwOaelQWmt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600014993440,"user_tz":-120,"elapsed":33505,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"ff30bac3-a3a1-4f28-ba08-4b11095e3f3d"},"source":["model = nn.Sequential(\n","    Lambda(preprocess),\n","    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n","    nn.ReLU(),\n","    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n","    nn.ReLU(),\n","    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n","    nn.ReLU(),\n","    nn.AvgPool2d(4),\n","    Lambda(lambda x: x.view(x.size(0), -1)),   \n",")\n","\n","opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n","\n","fit(epochs, model, loss_fn, opt, train_dl, valid_dl)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["0 0.3751671949386597\n","1 0.28894034023284915\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yyYWC4BhQzx2","colab_type":"text"},"source":["## Wrapping DataLoader\n","\n","Currently our CNN only works with MNIST, because\n","- It assumes the input is a 28*28 long vector\n","- It assumes that the final CNN grid size is 4*4 (since that’s the average pooling kernel size we used)\n","\n","Let’s get rid of these two assumptions, so our model works with any 2d single channel image. \n","\n","First, we can remove the initial Lambda layer but moving the data preprocessing into a generator:"]},{"cell_type":"code","metadata":{"id":"ercVUsWQTExu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014993441,"user_tz":-120,"elapsed":33498,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["def preprocess(x, y):\n","    return x.view(-1, 1, 28, 28), y\n","\n","class WrappedDataLoader:\n","    def __init__(self, dl, func):\n","        self.dl = dl\n","        self.func = func\n","\n","    def __len__(self):\n","        return len(self.dl)\n","\n","    def __iter__(self):\n","        batches = iter(self.dl)\n","        for b in batches:\n","            yield(self.func(*b))\n","\n","train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n","train_dl = WrappedDataLoader(train_dl, preprocess)\n","valid_dl = WrappedDataLoader(valid_dl, preprocess)"],"execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OvhrPZlLTrnv","colab_type":"text"},"source":["Next, we can replace `nn.AvgPool2d` with `nn.AdaptiveAvgPool2d`, which allows us to define the size of the output tensor we want, rather than the input tensor we have. As a result, our model will work with any size input."]},{"cell_type":"code","metadata":{"id":"sDwXthGJT_Z_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600014993441,"user_tz":-120,"elapsed":33493,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["model = nn.Sequential(\n","    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n","    nn.ReLU(),\n","    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n","    nn.ReLU(),\n","    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n","    nn.ReLU(),\n","    nn.AdaptiveAvgPool2d(1),\n","    Lambda(lambda x: x.view(x.size(0), -1)),\n",")"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-VjgqBjUBbj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600015003231,"user_tz":-120,"elapsed":43275,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"bec0adde-cbe0-44be-b4e2-e0c14f253023"},"source":["opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n","fit(epochs, model, loss_fn, opt, train_dl, valid_dl)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["0 0.35094336054325104\n","1 0.2842182375431061\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DYZogkcnUG55","colab_type":"text"},"source":["## Using your GPU\n","\n","First, check if our GPU is working in PyTorch:"]},{"cell_type":"code","metadata":{"id":"KEi_RYLYUnv7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600015003232,"user_tz":-120,"elapsed":43266,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"5f7c668a-ede6-4446-c49d-1d8c02c00252"},"source":["torch.cuda.is_available()"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"markdown","metadata":{"id":"jFZ94C0ZUq-g","colab_type":"text"},"source":["Then create a device object for it:"]},{"cell_type":"code","metadata":{"id":"r4w2Kp_kVINF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600015114683,"user_tz":-120,"elapsed":803,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":51,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x0pFO4KsVR5S","colab_type":"text"},"source":["Now let's update `preprocess` to move batches to the GPU:"]},{"cell_type":"code","metadata":{"id":"GAUjIShUVXx1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600015164212,"user_tz":-120,"elapsed":534,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["def preprocess(x, y):\n","    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\n","\n","train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n","train_dl = WrappedDataLoader(train_dl, preprocess)\n","valid_dl = WrappedDataLoader(valid_dl, preprocess)"],"execution_count":52,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ru1ltsXbVeDR","colab_type":"text"},"source":["And finally we can move our model to the GPU:"]},{"cell_type":"code","metadata":{"id":"_vuvS3V5VhRI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600015201258,"user_tz":-120,"elapsed":9724,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}}},"source":["model.to(dev)\n","opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t0QUvorFVk2g","colab_type":"text"},"source":["Our training should run faster now:"]},{"cell_type":"code","metadata":{"id":"jdh4QVeCVspQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600015234914,"user_tz":-120,"elapsed":3643,"user":{"displayName":"Tan Haobin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqV6KULf9q-EJYsjzgBomalLLjDtwO3xgi1rr1=s64","userId":"06394409417630818999"}},"outputId":"c778e000-9541-4805-bc71-af07e23e64bf"},"source":["fit(epochs, model, loss_fn, opt, train_dl, valid_dl)"],"execution_count":54,"outputs":[{"output_type":"stream","text":["0 0.243453067946434\n","1 0.17341095190346242\n"],"name":"stdout"}]}]}